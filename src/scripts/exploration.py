# %% [markdown]
# # üì∞ AI News Dataset Exploration
# 
# Explora√ß√£o inicial do dataset de not√≠cias sobre Intelig√™ncia Artificial.

# %% Imports e configura√ß√£o
import pandas as pd
import numpy as np
from pathlib import Path

# Configura√ß√£o do pandas para melhor visualiza√ß√£o
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', 100)

# %% Carregar o dataset
DATA_PATH = Path(__file__).parent.parent.parent / "data" / "bronze" / "ai_news.parquet"
df = pd.read_parquet(DATA_PATH)

print(f"‚úÖ Dataset carregado: {df.shape[0]:,} linhas √ó {df.shape[1]} colunas")

# %% [markdown]
# ## 1. Vis√£o Geral do Dataset

# %% Shape e tipos de dados
print("üìä SHAPE DO DATASET")
print("=" * 50)
print(f"Linhas:  {df.shape[0]:,}")
print(f"Colunas: {df.shape[1]}")
print()

print("üìã COLUNAS E TIPOS")
print("=" * 50)
print(df.dtypes)

# %% Primeiras linhas
print("\nüîç PRIMEIRAS 5 LINHAS")
print("=" * 50)
df.head()

# %% Valores nulos
print("\n‚ö†Ô∏è VALORES NULOS POR COLUNA")
print("=" * 50)
null_counts = df.isnull().sum()
null_pct = 100 * null_counts / len(df)
null_df = pd.DataFrame({
    'Nulos': null_counts,
    'Percentagem': null_pct.round(1)
})
print(null_df[null_df['Nulos'] > 0])

# %% [markdown]
# ## 2. An√°lise de Colunas Categ√≥ricas

# %% Distribui√ß√£o de t√≥picos
print("\nüìå DISTRIBUI√á√ÉO DE T√ìPICOS")
print("=" * 50)
topic_counts = df['topic'].value_counts()
print(topic_counts)

# %% Distribui√ß√£o de tags
print("\nüè∑Ô∏è DISTRIBUI√á√ÉO DE TAGS")
print("=" * 50)
print(df['tag'].value_counts())

# %% Distribui√ß√£o de √¢mbito
print("\nüåç DISTRIBUI√á√ÉO DE √ÇMBITO")
print("=" * 50)
print(df['√Çmbito'].value_counts())

# %% Top 10 fontes
print("\nüì∞ TOP 10 FONTES")
print("=" * 50)
print(df['source'].value_counts().head(10))

# %% [markdown]
# ## 3. An√°lise Temporal

# %% Converter datas
df['pubDate_parsed'] = pd.to_datetime(df['pubDate'], errors='coerce')
df['year'] = df['pubDate_parsed'].dt.year
df['month'] = df['pubDate_parsed'].dt.month
df['year_month'] = df['pubDate_parsed'].dt.to_period('M')

# %% Range temporal
print("\nüìÖ RANGE TEMPORAL")
print("=" * 50)
print(f"Data mais antiga: {df['pubDate_parsed'].min()}")
print(f"Data mais recente: {df['pubDate_parsed'].max()}")

# %% Distribui√ß√£o por ano
print("\nüìÜ NOT√çCIAS POR ANO")
print("=" * 50)
print(df['year'].value_counts().sort_index())

# %% [markdown]
# ## 4. An√°lise de Texto

# %% Comprimento dos t√≠tulos e descri√ß√µes
df['title_len'] = df['title'].str.len()
df['description_len'] = df['description'].str.len()

print("\nüìù ESTAT√çSTICAS DE COMPRIMENTO DE TEXTO")
print("=" * 50)
print(df[['title_len', 'description_len']].describe())

# %% Exemplo de t√≠tulos por t√≥pico
print("\nüì∞ EXEMPLOS DE T√çTULOS POR T√ìPICO")
print("=" * 50)
for topic in df['topic'].unique()[:5]:
    print(f"\n--- {topic} ---")
    sample_titles = df[df['topic'] == topic]['title'].head(3).tolist()
    for title in sample_titles:
        print(f"  ‚Ä¢ {title[:80]}...")

# %% [markdown]
# ## 5. Prepara√ß√£o para Clustering
# 
# Pr√≥ximos passos:
# - Limpeza e normaliza√ß√£o de texto
# - Vectoriza√ß√£o (TF-IDF, embeddings)
# - Clustering (K-Means, HDBSCAN)
# - Avalia√ß√£o de clusters

# %% Resumo das colunas √∫teis para clustering
print("\nüéØ COLUNAS √öTEIS PARA CLUSTERING")
print("=" * 50)
print("""
Texto principal:
  ‚Ä¢ title - T√≠tulo da not√≠cia
  ‚Ä¢ description - Corpo/descri√ß√£o da not√≠cia

Metadados para an√°lise:
  ‚Ä¢ topic - T√≥pico atribu√≠do (21 valores √∫nicos) - pode servir como ground truth
  ‚Ä¢ tag - Tag atribu√≠da (3 valores √∫nicos)
  ‚Ä¢ source - Fonte da not√≠cia (908 fontes)
  ‚Ä¢ pubDate - Data de publica√ß√£o
  ‚Ä¢ √Çmbito - √Çmbito geogr√°fico/tem√°tico (18 valores √∫nicos)
""")

# %% Verificar unicidade de topic vs tag
print("\nüîó RELA√á√ÉO TOPIC vs TAG")
print("=" * 50)
topic_tag = df.groupby('topic')['tag'].unique()
print(topic_tag)
